model:
  learning_rate: 0.0001
  target: ldm.models.diffusion.dual_cond_ddpm.DualCondLDM
  params:
    style_dim: 2944
    linear_start: 0.0015
    linear_end: 0.0195
    timesteps: 1000
    cond_stage_key: content_and_std_mean
    image_size: 16
    channels: 16
    cond_stage_trainable: false
    conditioning_key:
    - other
    - other
    cond_stage_config: __is_adaptive__
    scale_factors: [
      [ 0.3335, 0.1840, 0.3386, 0.3695, 0.3052, 0.3254, 0.3262, 0.2794,
        0.3670, 0.3812, 0.2283, 0.3122, 0.3555, 0.3291, 0.3485, 0.3699 ],
    ]
    shift_values: [
      [ -0.7449, -0.4035,  0.4347, -0.2002, -0.4501,  0.4839, -1.0560,  1.5971,
        0.4377, -1.4263, -0.3681, -1.1490,  0.1817, -0.2732, -1.2297, -0.3025 ],
    ]
    unet_config:
      target: ldm.modules.diffusionmodules.model.StyleUNetModel
      params:
        image_size: 16
        in_channels: 16
        out_channels: 16
        content_in_dim: 16
        content_refined_dim: 12
        model_channels: 384
        attention_resolutions:
        - 1
        - 2
        num_res_blocks: 2
        channel_mult:
        - 1
        - 2
        context_dim: 2944
        num_head_channels: 64
    first_stage_config:
      target: ldm.models.autoencoder.AutoencoderKL
      params:
        embed_dim: 16
        ckpt_path: checkpoints/kl-f16.ckpt
        ddconfig:
          encoder_target: ldm.modules.vae.model.Encoder
          decoder_target: ldm.modules.vae.model.Decoder
          params:
            double_z: true
            z_channels: 16
            resolution: 256
            in_channels: 3
            out_ch: 3
            ch: 128
            ch_mult:
            - 1
            - 1
            - 2
            - 2
            - 4
            num_res_blocks: 2
            attn_resolutions:
            - 16
            dropout: 0.0
        lossconfig:
          target: ldm.modules.losses.contperceptual.DummyLoss
data:
  target: main.DataModuleFromConfig
  params:
    batch_size: 16
    num_workers: 10
    wrap: true
    train:
      target: ldm.data.wikiart.HybridTrain
      params:
        random_augment: true
        style_size: 512
        style_crop_size: 256
        content_drop: 0.5
        style_drop: 0.1
lightning:
  callbacks:
    image_logger:
      target: main.ImageLogger
      params:
        frequency_base: 4
        batch_frequency: 4096
  modelcheckpoint_step:
    params:
      every_n_train_steps: 25000
  modelcheckpoint_epoch:
    params:
      every_n_epochs: 25
  trainer:
    max_epochs: 1000
    log_every_n_steps: 16
    accumulate_grad_batches: 8
